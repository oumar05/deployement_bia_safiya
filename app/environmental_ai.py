import os
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from PIL import Image
import cv2
import logging
from typing import Tuple, Dict, Any
from django.conf import settings

logger = logging.getLogger(__name__)

class EnvironmentalImageClassifier:
    """
    Service d'IA pour classifier les images selon leur contenu environnemental
    Utilise MobileNetV2 prÃ©-entraÃ®nÃ© sur ImageNet
    """
    
    def __init__(self):
        self.model = None
        self.is_loaded = False
        self.model_url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"
        
        # CatÃ©gories environnementales acceptÃ©es (indices ImageNet)
        self.environmental_categories = {
            # Nature et paysages
            'forest': [968, 969, 970], # forÃªt
            'tree': [986, 987, 988, 989], # arbres
            'mountain': [974, 975, 976], # montagnes
            'water': [625, 626, 627, 628], # eau, riviÃ¨res, lacs
            'beach': [978, 979], # plage
            'flower': [985], # fleurs
            
            # Animaux
            'bird': list(range(80, 101)), # oiseaux
            'fish': list(range(389, 397)), # poissons
            'mammal': list(range(285, 310)), # mammifÃ¨res
            'insect': list(range(318, 328)), # insectes
            
            # Agriculture
            'farm': [408, 409], # ferme
            'vegetable': [936, 937, 938], # lÃ©gumes
            'fruit': [948, 949, 950, 951], # fruits
        }
        
        # CatÃ©gories Ã  rejeter
        self.forbidden_categories = {
            # Sports
            'sports': list(range(768, 795)), # Ã©quipements sportifs
            'ball': [722, 723, 724, 725], # ballons
            
            # Divertissement
            'music': [420, 421, 422], # instruments
            'entertainment': [438, 439, 440], # divertissement
            
            # Mode et luxe
            'clothing': list(range(450, 520)), # vÃªtements
            'jewelry': [695, 696], # bijoux
            
            # VÃ©hicules non-Ã©cologiques
            'vehicle': list(range(565, 580)), # voitures normales
        }

    async def load_model(self):
        """Charge le modÃ¨le MobileNetV2"""
        try:
            if self.is_loaded:
                return True
                
            logger.info("ðŸš€ Chargement du modÃ¨le MobileNetV2...")
            
            # Charger le modÃ¨le depuis TensorFlow Hub
            self.model = hub.load(self.model_url)
            self.is_loaded = True
            
            logger.info("âœ… ModÃ¨le MobileNetV2 chargÃ© avec succÃ¨s !")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors du chargement du modÃ¨le: {e}")
            return False

    def preprocess_image(self, image_path: str) -> np.ndarray:
        """PrÃ©processe l'image pour le modÃ¨le"""
        try:
            # Charger l'image
            image = Image.open(image_path).convert('RGB')
            
            # Redimensionner Ã  224x224 (taille attendue par MobileNetV2)
            image = image.resize((224, 224))
            
            # Convertir en array numpy
            image_array = np.array(image)
            
            # Normaliser (0-255 vers 0-1)
            image_array = image_array.astype(np.float32) / 255.0
            
            # Ajouter la dimension batch
            image_array = np.expand_dims(image_array, axis=0)
            
            return image_array
            
        except Exception as e:
            logger.error(f"âŒ Erreur prÃ©processing image: {e}")
            raise

    async def classify_image(self, image_path: str) -> Dict[str, Any]:
        """Classifie une image et dÃ©termine si elle est environnementale"""
        try:
            if not self.is_loaded:
                await self.load_model()
            
            logger.info(f"ðŸ” Analyse de l'image: {image_path}")
            
            # PrÃ©processer l'image
            processed_image = self.preprocess_image(image_path)
            
            # PrÃ©diction
            predictions = self.model(processed_image)
            probabilities = tf.nn.softmax(predictions[0])
            
            # Obtenir les top 5 prÃ©dictions
            top_k = tf.nn.top_k(probabilities, k=5)
            top_classes = top_k.indices.numpy()
            top_scores = top_k.values.numpy()
            
            # Analyser si c'est environnemental
            is_environmental = self._analyze_environmental_content(top_classes, top_scores)
            
            # Score de confiance
            confidence_score = float(np.max(top_scores))
            
            result = {
                'is_environmental': is_environmental,
                'confidence': confidence_score,
                'top_predictions': [
                    {
                        'class_id': int(class_id),
                        'score': float(score)
                    }
                    for class_id, score in zip(top_classes, top_scores)
                ],
                'explanation': self._get_explanation(top_classes, is_environmental)
            }
            
            logger.info(f"âœ… RÃ©sultat: {'AcceptÃ©e' if is_environmental else 'RejetÃ©e'} (confiance: {confidence_score:.2f})")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la classification: {e}")
            return {
                'is_environmental': False,
                'confidence': 0.0,
                'error': str(e)
            }

    def _analyze_environmental_content(self, top_classes: np.ndarray, top_scores: np.ndarray) -> bool:
        """Analyse si le contenu est environnemental basÃ© sur les prÃ©dictions"""
        
        # VÃ©rifier d'abord si c'est du contenu interdit
        for class_id, score in zip(top_classes, top_scores):
            if score > 0.3:  # Seuil de confiance
                for category, forbidden_ids in self.forbidden_categories.items():
                    if class_id in forbidden_ids:
                        logger.info(f"ðŸš« Contenu interdit dÃ©tectÃ©: {category} (score: {score:.2f})")
                        return False
        
        # VÃ©rifier si c'est du contenu environnemental
        environmental_score = 0.0
        for class_id, score in zip(top_classes, top_scores):
            for category, env_ids in self.environmental_categories.items():
                if class_id in env_ids:
                    environmental_score += score
                    logger.info(f"ðŸŒ± Contenu environnemental dÃ©tectÃ©: {category} (score: {score:.2f})")
        
        # DÃ©cision basÃ©e sur le score environnemental
        return environmental_score > 0.4  # Seuil d'acceptation

    def _get_explanation(self, top_classes: np.ndarray, is_environmental: bool) -> str:
        """GÃ©nÃ¨re une explication de la dÃ©cision"""
        if is_environmental:
            return "Image acceptÃ©e: Contenu environnemental dÃ©tectÃ© (nature, animaux, Ã©cologie)"
        else:
            # VÃ©rifier la raison du rejet
            for class_id in top_classes:
                for category, forbidden_ids in self.forbidden_categories.items():
                    if class_id in forbidden_ids:
                        return f"Image rejetÃ©e: Contenu de type '{category}' dÃ©tectÃ©"
            
            return "Image rejetÃ©e: Contenu non-environnemental"

    async def batch_classify(self, image_paths: list) -> Dict[str, Any]:
        """Classifie plusieurs images en lot"""
        results = {
            'total': len(image_paths),
            'accepted': 0,
            'rejected': 0,
            'details': []
        }
        
        for image_path in image_paths:
            result = await self.classify_image(image_path)
            
            if result.get('is_environmental', False):
                results['accepted'] += 1
            else:
                results['rejected'] += 1
            
            results['details'].append({
                'image': image_path,
                'result': result
            })
        
        return results

# Instance globale du classificateur
environmental_classifier = EnvironmentalImageClassifier()
